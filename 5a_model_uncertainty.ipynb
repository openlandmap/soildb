{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058646f4-f721-4301-aeee-9fb59ce0f1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "import warnings\n",
    "import multiprocess as mp\n",
    "import time\n",
    "from scipy.special import expit, logit\n",
    "import warnings\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, HalvingGridSearchCV, KFold, GroupKFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer#, root_mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from cubist import Cubist\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pathlib import Path\n",
    "from trees_rf import TreesRandomForestRegressor\n",
    "from model_fit import read_features, cfi_calc, parameter_fine_tuning, calc_ccc, separate_data, rscfi \n",
    "from model_fit import accuracy_plot, plot_top_features, pdp_hexbin, plot_histogram, calc_metrics, accuracy_strata_plot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox \n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "folder_path = '/mnt/ripley/global_soc/scikit-map/global-soil-mapping'\n",
    "# prop_list = ['ocd', 'soc', 'bulk.density', 'ph.h2o' ,'coarse']\n",
    "prop_list = ['ocd', 'soc', 'bulk.density', 'ph.h2o']\n",
    "transforms_dict = {\n",
    "    'ocd': 'log1p',\n",
    "    'soc': 'log1p',\n",
    "    'bulk.density': None,\n",
    "    'ph.h2o': None,\n",
    "    'coarse': 'log1p'\n",
    "}\n",
    "\n",
    "\n",
    "version = '20250204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72e2a8a-2983-490d-b67a-a92f8c647b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_picp(lower_bounds, upper_bounds, true_values):\n",
    "    within_bounds = np.sum((true_values >= lower_bounds) & (true_values <= upper_bounds))\n",
    "    picp = within_bounds / len(true_values)\n",
    "    return picp\n",
    "\n",
    "def calc_qcp(predictions, true_values, quantile):\n",
    "    return np.mean(true_values <= predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcc853-8d42-49be-93e0-0132c3fc55a5",
   "metadata": {},
   "source": [
    "# Uncertainty evaluation\n",
    "### this is only done for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891eecae-7db8-4abf-8aca-2b40645203d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "texture1--------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/ripley/global_soc/scikit-map/global-soil-mapping/textures/texture1/data_train_texture1_v20250204.pq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m prop\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# read in material--------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data_train_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprop\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mversion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pq\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m covs \u001b[38;5;241m=\u001b[39m read_features(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/feature_selected_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# read in\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:220\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilesystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    228\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:110\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/ripley/global_soc/scikit-map/global-soil-mapping/textures/texture1/data_train_texture1_v20250204.pq'"
     ]
    }
   ],
   "source": [
    "from trees_rf import cast_tree_rf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for prop in prop_list:\n",
    "    print(f'\\n{prop}--------------------------------------------------------------')\n",
    "    space = transforms_dict[prop]\n",
    "    output_folder = folder_path+'/'+prop\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    if space=='log1p':\n",
    "        # df.loc[:,f'{prop}_log1p'] = np.log1p(df[prop])\n",
    "        tgt = f'{prop}_log1p'\n",
    "    elif space=='boxcox':\n",
    "        # df.loc[:,f'{prop}_log1p'] = np.log1p(df[prop])\n",
    "        tgt = f'{prop}_boxcox'\n",
    "        cal[f'{prop}_boxcox'], fitted_lambda = boxcox(cal['ocd'], lmbda=None)\n",
    "    else:\n",
    "        tgt = prop\n",
    "    \n",
    "    # read in material--------------------------------------------------------------\n",
    "    # data\n",
    "    train = pd.read_parquet(f'{output_folder}/data_train_{prop}_v{version}.pq')\n",
    "    test = pd.read_parquet(f'{output_folder}/data_test_{prop}_v{version}.pq')\n",
    "    covs = read_features(f'{output_folder}/feature_selected_{prop}_v{version}.txt') # read in\n",
    "    test = test.dropna(subset=covs,how='any')\n",
    "    train = train.dropna(subset=covs,how='any')\n",
    "    \n",
    "    # models\n",
    "    model = joblib.load(f'{output_folder}/model_rf.{prop}_ccc_v{version}.joblib')\n",
    "    model.n_jobs = 90\n",
    "    model.fit(train[covs], train[tgt])\n",
    "    model = cast_tree_rf(model)\n",
    "    \n",
    "    # tree predictions\n",
    "    tree_predictions = model.predict(test[covs])\n",
    "    y_pred = np.mean(tree_predictions, axis=0) # get the mean before transformation\n",
    "    if space=='log1p':\n",
    "        y_pred = np.expm1(y_pred)\n",
    "        # calculate quantiles to form an accuracy plots\n",
    "        tree_predictions = np.expm1(tree_predictions) # tranform before getting the percentile\n",
    "    \n",
    "    quantiles = [0.005, 0.025, 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.495, 0.5 , 0.505, 0.55,\n",
    "                 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 0.975, 0.995]\n",
    "    y_q = np.percentile(tree_predictions, [q * 100 for q in quantiles], axis=0)\n",
    "    qcp = []\n",
    "    for ii in range(len(quantiles)):\n",
    "        qcp.append(calc_qcp(y_q[ii], test[prop], quantiles[ii]))\n",
    "\n",
    "    # calculate piw, picp\n",
    "    pi = []\n",
    "    picp = []\n",
    "    piw_m = []\n",
    "    piw_med = []\n",
    "    for ii in range(12):\n",
    "        jj = len(quantiles)-1-ii\n",
    "        pi.append(round(1-quantiles[ii]*2,2))\n",
    "        picp.append(calc_picp(y_q[ii,:], y_q[jj,:], test[prop]))\n",
    "        piw_m.append(np.mean(y_q[jj,:]-y_q[ii,:]))\n",
    "        piw_med.append(np.median(y_q[jj,:]-y_q[ii,:]))\n",
    "        \n",
    "    # calculate PICP for target PI (+- 1 std): 68%, P16-P84\n",
    "    target_pi = [0.16, 0.84]\n",
    "    pib = np.percentile(tree_predictions, [q * 100 for q in target_pi], axis=0)\n",
    "    target_picp = calc_picp(pib[0], pib[1], test[prop])\n",
    "\n",
    "    # plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n",
    "    axs[0].plot(quantiles, quantiles, label='1:1 line')\n",
    "    axs[0].scatter(quantiles, qcp, color='black')\n",
    "    axs[0].set_xlabel('Target quantiles', fontsize=20)\n",
    "    axs[0].set_ylabel('QCP', fontsize=20)\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend(fontsize=20, frameon=False)  # Make legend background transparent\n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    axs[1].axvline(x=0.68, color='orange', linestyle='--', linewidth=2, label=f'Target PI 68%:\\nPICP {target_picp*100:.0f}%')  # Use axvline to draw a vertical line across the entire plot\n",
    "    axs[1].plot(pi, pi, label='1:1 line')\n",
    "    axs[1].scatter(pi, picp, color='black')\n",
    "    axs[1].set_xlabel('PI', fontsize=20)\n",
    "    axs[1].set_ylabel('PICP', fontsize=20)\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend(fontsize=20, frameon=False)  # Make legend background transparent\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3)  \n",
    "    plt.savefig(f'{output_folder}/plot_acuracy.uncertainty_{prop}_v{version}.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5139990-fbad-4e84-88aa-da1908ba99f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
